# app.py (v5.4 GitHub Compatible) â€“ CSV columns: store_id,name,sales_id,order_date,item_id,quantity,price
# GitHubç¯å¢ƒå…¼å®¹ä¿®å¤:
# - ç§»é™¤ Python 3.10+ ç±»å‹æ³¨è§£è¯­æ³•
# - æ·»åŠ  pdftotext æ›¿ä»£æ–¹æ¡ˆ (PyPDF2)
# - å¢å¼ºé”™è¯¯å¤„ç†

import re
import tempfile
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any
import io

import streamlit as st
import pandas as pd

# å°è¯•å¯¼å…¥PDFå¤„ç†åº“
try:
    import PyPDF2
    PDF_FALLBACK_AVAILABLE = True
except ImportError:
    PDF_FALLBACK_AVAILABLE = False

st.set_page_config(page_title="PO PDF â†’ CSV (GitHubç‰ˆ)", layout="wide")
st.title("PO PDF â†’ CSVï¼ˆGitHubå…¼å®¹ç‰ˆï¼‰")

VENDOR_PROFILES = {
    "Foodstuffs_NI": {
        "detect_keywords": ["Foodstuffs North Island Limited", "Order Forecast", "O/F"],
        "store_regex": r"(?:Delivery\s+To|Delivery\s+Address)[:ï¼š]?\s*([^\n]+)",
        "header_extract": {
            "PO_Number": r"Order\s+Forecast\s+Number[:ï¼š]?\s*([0-9]+)",
            "Order_Date": r"Date\s+of\s+Order[:ï¼š]?\s*([0-9]{1,2}/[0-9]{1,2}/[0-9]{2,4})",
            "Delivery_Date": r"Delivery\s+Date[:ï¼š]?\s*([0-9]{1,2}/[0-9]{1,2}/[0-9]{2,4})"
        }
    },
    "WWNZ": {
        "detect_keywords": ["WOOLWORTHS NZ", "WOOLWORTHS NEW ZEALAND", "PRODUCE ORDER NUMBER", "VENDOR COPY"],
        "store_regex": r"Deliver\s+To:\s*([0-9]{3,6})\s*\n\s*([^\n]+)",
        "header_extract": {
            "PO_Number": r"PRODUCE\s+ORDER\s+NUMBER\s*:\s*([0-9]+)",
            "Order_Date": r"Order\s+Date\s*:\s*([0-9]{1,2}/[0-9]{1,2}/[0-9]{2,4})",
            "Delivery_Date": r"Delivery\s+Date\s*:\s*([0-9]{1,2}/[0-9]{1,2}/[0-9]{2,4})"
        }
    },
    "MyFoodBag": {
        "detect_keywords": ["My Food Bag", "My Food Bag Limited", "GST Reg. No:"],
        "store_regex": r"(My\s*Food\s*Bag[\s\S]{0,200}?Christchurch\s*8042)",
        "header_extract": {
            "PO_Number": r"Purchase\s+(?:Order\s+)?No[:ï¼š]?\s*([0-9]+)",
            "Order_Date": r"Order\s*Date[:ï¼š]?\s*([0-9]{1,2}/[0-9]{1,2}/[0-9]{2,4})"
        }
    }
}

# ---------- PDFå¤„ç†å‡½æ•° ----------
def extract_pdf_text(pdf_path: str) -> str:
    """å°è¯•å¤šç§æ–¹æ³•æå–PDFæ–‡æœ¬"""
    
    # æ–¹æ³•1: å°è¯• pdftotext (å¦‚æœå¯ç”¨)
    try:
        out = subprocess.check_output(
            ["pdftotext", "-layout", pdf_path, "-"], 
            stderr=subprocess.STDOUT,
            timeout=30
        )
        text = out.decode("utf-8", errors="ignore")
        if text.strip():
            return text
    except Exception:
        pass
    
    # æ–¹æ³•2: PyPDF2 å¤‡ç”¨æ–¹æ¡ˆ
    if PDF_FALLBACK_AVAILABLE:
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                if text.strip():
                    return text
        except Exception as e:
            st.warning(f"PyPDF2 æå–å¤±è´¥: {e}")
    
    return ""

def extract_pdf_from_bytes(pdf_bytes: bytes) -> str:
    """ç›´æ¥ä»å­—èŠ‚æ•°æ®æå–PDFæ–‡æœ¬"""
    
    # æ–¹æ³•1: ä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨ pdftotext
    try:
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp:
            tmp.write(pdf_bytes)
            tmp.flush()
            return extract_pdf_text(tmp.name)
    except Exception:
        pass
    
    # æ–¹æ³•2: PyPDF2 ç›´æ¥å¤„ç†å­—èŠ‚æµ
    if PDF_FALLBACK_AVAILABLE:
        try:
            pdf_stream = io.BytesIO(pdf_bytes)
            pdf_reader = PyPDF2.PdfReader(pdf_stream)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            st.warning(f"PyPDF2 å­—èŠ‚æµå¤„ç†å¤±è´¥: {e}")
    
    return ""

# ---------- è¾…åŠ©å‡½æ•° ----------
def parse_date_safe(s: str) -> Optional[str]:
    if not s:
        return None
    for fmt in ("%d/%m/%Y", "%d/%m/%y", "%Y/%m/%d", "%d-%m-%Y", "%Y-%m-%d"):
        try:
            return datetime.strptime(s.strip(), fmt).date().isoformat()
        except Exception:
            continue
    return s

def extract(pattern: str, text: str, flags=re.I|re.S) -> Optional[str]:
    if not pattern or not text:
        return None
    m = re.search(pattern, text, flags=flags)
    if not m:
        return None
    return m.group(1).strip() if m.lastindex else m.group(0).strip()

def detect_vendor(text_concat: str) -> Optional[str]:
    if not text_concat:
        return None
    
    t = text_concat.upper()
    # prefer WWNZ first
    if any(kw in t for kw in [k.upper() for k in VENDOR_PROFILES["WWNZ"]["detect_keywords"]]):
        return "WWNZ"
    for v in ("Foodstuffs_NI","MyFoodBag"):
        if any(kw.upper() in t for kw in VENDOR_PROFILES[v]["detect_keywords"]):
            return v
    return None

def keyword_hits(text: str) -> Dict[str, int]:
    text_u = (text or '').upper()
    def count(keys):
        return sum(text_u.count(k.upper()) for k in keys)
    return {
        'Foodstuffs_NI': count(VENDOR_PROFILES['Foodstuffs_NI']['detect_keywords']),
        'WWNZ': count(VENDOR_PROFILES['WWNZ']['detect_keywords']),
        'MyFoodBag': count(VENDOR_PROFILES['MyFoodBag']['detect_keywords'])
    }

def normalize_numeric(series):
    if series is None or len(series) == 0:
        return pd.Series(dtype=float)
    
    s = pd.Series(series)
    s = s.apply(lambda x: (x[0] if isinstance(x, (list, tuple)) and len(x)>0 else x))
    s = s.astype(str).str.replace(r"[\s,\$]", "", regex=True)
    s = s.str.extract(r"(-?\d+(?:\.\d+)?)", expand=False)
    return pd.to_numeric(s, errors="coerce")

def clean_store_name(vendor: str, raw_name: Optional[str]) -> Optional[str]:
    """æ¸…ç†åº—é“ºåç§°"""
    if not raw_name:
        return raw_name
        
    if vendor == "WWNZ":
        # ç§»é™¤ä¾›åº”å•†ç¼–å·ç­‰é¢å¤–æ–‡æœ¬
        cleaned = re.sub(r'\d{4}-?\s*-?\s*Vendor\s*Number:?\s*\d+', '', raw_name)
        cleaned = re.sub(r'^\d{3,5}\s*\n?\s*', '', cleaned)
        return cleaned.strip()
    
    return raw_name.strip() if raw_name else raw_name

def store_lookup(name_text: str, store_map_df: Optional[pd.DataFrame]):
    """æŸ¥æ‰¾åº—é“ºID"""
    if store_map_df is None or not name_text:
        return None, None
    
    try:
        df = store_map_df.copy()
        df.columns = [c.strip().lower() for c in df.columns]
        key = str(name_text).strip().lower()
        
        # æ­£å‘åŒ…å«åŒ¹é…
        m = df[df.get("name","").astype(str).str.lower().str.contains(re.escape(key[:40]), na=False)]
        if not m.empty:
            return m.iloc[0].get("store_id"), m.iloc[0].get("name")
        
        # åå‘åŒ…å«åŒ¹é…
        m = df[df.get("name","").astype(str).str.lower().apply(lambda x: key in x if x else False)]
        if not m.empty:
            return m.iloc[0].get("store_id"), m.iloc[0].get("name")
        
        return None, None
    except Exception as e:
        st.warning(f"åº—é“ºæŸ¥æ‰¾é”™è¯¯: {e}")
        return None, None

# ---------- ä¾›åº”å•†è§£æå™¨ ----------
def parse_foodstuffs(text: str) -> pd.DataFrame:
    """è§£æ Foodstuffs PDF"""
    pat = re.compile(
        r"^\s*\d+\s+(?P<article>\d{6,})\s+[A-Z0-9$]+\s+.+?\s+(?P<qty>\d+)\s+[A-Z]{2,4}\s+\d+\s+\$?(?P<price>[\d,]+\.\d{2}).*?\$?[\d,]+\.\d{2}\s*$",
        re.I
    )
    rows = []
    for ln in text.splitlines():
        m = pat.match(ln)
        if m:
            rows.append({
                "item_id": m.group("article"),
                "quantity": m.group("qty"),
                "price": m.group("price").replace(',', ''),
            })
    return pd.DataFrame(rows)

def parse_wwnz(text: str) -> pd.DataFrame:
    """è§£æ WWNZ PDF - ä¿®å¤ä»·æ ¼æå–"""
    rows = []
    lines = text.splitlines()
    
    # æŸ¥æ‰¾æ•°æ®éƒ¨åˆ†
    data_started = False
    for ln in lines:
        # æŸ¥æ‰¾è¡¨å¤´
        if re.search(r'LINE.*ITEM NO.*ORD QTY.*PRICE', ln, re.I):
            data_started = True
            continue
            
        if not data_started:
            continue
            
        # é‡åˆ°æ€»è®¡æ—¶åœæ­¢
        if re.search(r'Order Totals|Total Value', ln, re.I):
            break
            
        # è§£ææ•°æ®è¡Œ - æ›´çµæ´»çš„æ¨¡å¼
        match = re.match(r'^\s*(\d+)\s+(\d{8,14})\s+(.*?)\s+(\d{5,})\s+([\d.]+)\s+(\S+)\s+(\d+)\s+(\d+)\s+([\d.]+)', ln.strip())
        
        if match:
            line_no, gtin, desc, item_no, tu, sfx, om, qty, price = match.groups()
            rows.append({
                "item_id": item_no,
                "quantity": qty,
                "price": price,
            })
    
    return pd.DataFrame(rows)

def parse_mfb(text: str) -> pd.DataFrame:
    """è§£æ MyFoodBag PDF - ä¿®å¤æ•°é‡æå–"""
    rows = []
    lines = [ln.rstrip() for ln in text.splitlines() if ln.strip()]
    
    # æŸ¥æ‰¾åŒ…å« Item No, QTY ç­‰çš„è¡¨å¤´
    header_found = False
    for i, ln in enumerate(lines):
        if re.search(r'item\s*no.*qty.*description', ln, re.I):
            header_found = True
            # ä»ä¸‹ä¸€è¡Œå¼€å§‹å¤„ç†æ•°æ®
            for data_line in lines[i+1:]:
                # é‡åˆ°æ€»è®¡æˆ–ç»“æŸæ ‡è®°æ—¶åœæ­¢
                if re.search(r'\btotal\b|balance\s+due|page\s+\d+', data_line, re.I):
                    break
                
                # æŸ¥æ‰¾ä»¥ç‰©å“ç¼–å·å¼€å¤´çš„è¡Œ (MFB æ ¼å¼ä¸º 10xxxxxxx)
                if re.match(r'^\s*10\d{6,}', data_line):
                    # ä»”ç»†åˆ†å‰²è¡Œ
                    parts = re.split(r'\s{2,}', data_line.strip())
                    
                    if len(parts) >= 5:  # Item No, QTY, Description, Date, Price, [Total]
                        item_no = parts[0].strip()
                        qty = parts[1].strip()
                        price = parts[4].strip() if len(parts) > 4 else parts[-2].strip()
                        
                        # æ¸…ç†æ•°å€¼
                        qty = re.sub(r'[^\d.]', '', qty)
                        price = re.sub(r'[^\d.]', '', price)
                        
                        if qty and price and item_no:
                            rows.append({
                                "item_id": item_no,
                                "quantity": qty,
                                "price": price
                            })
            break
    
    return pd.DataFrame(rows)

def validate_dataframe(df: pd.DataFrame, vendor_name: str) -> pd.DataFrame:
    """éªŒè¯å’Œæ¸…ç†è§£æåçš„æ•°æ®æ¡†"""
    if df.empty:
        return df
    
    # ç§»é™¤å®Œå…¨ç©ºçš„è¡Œ
    df = df.dropna(how='all')
    
    # ç§»é™¤æ²¡æœ‰ item_id çš„è¡Œ
    df = df[df['item_id'].notna() & (df['item_id'] != '')]
    
    # ç¡®ä¿æ•°å­—åˆ—æ ¼å¼æ­£ç¡®
    if 'quantity' in df.columns:
        df['quantity'] = normalize_numeric(df['quantity'])
    if 'price' in df.columns:
        df['price'] = normalize_numeric(df['price'])
    
    # ç§»é™¤æ— æ•ˆæ•°æ®çš„è¡Œ
    df = df[(df.get('quantity', 0) > 0) & (df.get('price', 0) > 0)]
    
    return df.reset_index(drop=True)

# ---------- Streamlit ç•Œé¢ ----------
with st.sidebar:
    st.header("é€‰é¡¹")
    vendor_choice = st.selectbox("ä¾›åº”å•†", ["Auto","Foodstuffs_NI","WWNZ","MyFoodBag"], index=0)
    
    # PDFå¤„ç†çŠ¶æ€æ˜¾ç¤º
    if not PDF_FALLBACK_AVAILABLE:
        st.warning("âš ï¸ PyPDF2 æœªå®‰è£…ï¼Œä»…æ”¯æŒ pdftotext")
        st.code("pip install PyPDF2")
    
    store_map_file = st.file_uploader("ä¸Šä¼  store_map.csvï¼ˆåˆ—ï¼šname,store_idï¼‰", type=["csv"])
    
    store_map_df = None
    if store_map_file:
        try:
            store_map_df = pd.read_csv(store_map_file)
            # éªŒè¯å¿…éœ€åˆ—
            required_cols = ['name', 'store_id']
            missing_cols = [col for col in required_cols if col not in store_map_df.columns]
            if missing_cols:
                st.error(f"store_map.csv ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
                store_map_df = None
            else:
                st.success(f"âœ… å·²åŠ è½½é—¨åº—æ˜ å°„ï¼Œå…± {len(store_map_df)} æ¡è®°å½•")
        except Exception as e:
            st.error(f"store_map è¯»å–å¤±è´¥ï¼š{e}")

uploaded = st.file_uploader("ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª PO PDF", type=["pdf"], accept_multiple_files=True)

# ---------- ä¸»å¤„ç†é€»è¾‘ ----------
results = []
if uploaded:
    progress_bar = st.progress(0)
    
    for idx, f in enumerate(uploaded):
        progress_bar.progress((idx + 1) / len(uploaded))
        
        # æå–PDFæ–‡æœ¬
        text = extract_pdf_from_bytes(f.read())
        
        if not text or not text.strip():
            st.error(f"âŒ {f.name}: PDF æ–‡æœ¬æå–å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æ‰«æç‰ˆæˆ–åŠ å¯†çš„PDFï¼‰")
            continue

        # ä¾›åº”å•†è¯†åˆ«
        hits = keyword_hits(text)
        active_vendor = detect_vendor(text) if vendor_choice == "Auto" else vendor_choice

        # è‡ªåŠ¨å›é€€ï¼šå°è¯•æ‰€æœ‰è§£æå™¨å¹¶é€‰æ‹©ç»“æœæœ€å¤šçš„
        body = None
        chosen_by_rows = None
        if active_vendor is None and vendor_choice == "Auto":
            fs_df = validate_dataframe(parse_foodstuffs(text), "Foodstuffs_NI")
            ww_df = validate_dataframe(parse_wwnz(text), "WWNZ")
            mfb_df = validate_dataframe(parse_mfb(text), "MyFoodBag")
            
            sizes = {'Foodstuffs_NI': len(fs_df), 'WWNZ': len(ww_df), 'MyFoodBag': len(mfb_df)}
            if any(sizes.values()):
                chosen_by_rows = max(sizes, key=lambda k: sizes[k])
                active_vendor = chosen_by_rows
                body = {'Foodstuffs_NI': fs_df, 'WWNZ': ww_df, 'MyFoodBag': mfb_df}[chosen_by_rows]

        if active_vendor is None:
            st.error(f"âŒ {f.name}: æœªè¯†åˆ«ä¾›åº”å•†ï¼ˆå…³é”®è¯å‘½ä¸­ï¼š{hits}ï¼‰ã€‚è¯·åœ¨å·¦ä¾§æ‰‹åŠ¨é€‰æ‹©ä¾›åº”å•†ã€‚")
            continue

        # æå–å¤´éƒ¨ä¿¡æ¯
        prof = VENDOR_PROFILES[active_vendor]
        sales_id = extract(prof["header_extract"].get("PO_Number"), text)
        order_date = extract(prof["header_extract"].get("Delivery_Date") or prof["header_extract"].get("Order_Date"), text)
        order_date = parse_date_safe(order_date)
        
        # æå–å¹¶æ¸…ç†åº—é“ºåç§°
        raw_name = extract(prof["store_regex"], text)
        name_txt = clean_store_name(active_vendor, raw_name)

        # è§£æä¾›åº”å•†æ•°æ®ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰
        if body is None:
            try:
                if active_vendor == "Foodstuffs_NI":
                    body = parse_foodstuffs(text)
                elif active_vendor == "WWNZ":
                    body = parse_wwnz(text)
                else:
                    body = parse_mfb(text)
                
                body = validate_dataframe(body, active_vendor)
            except Exception as e:
                st.error(f"âŒ {f.name}: è§£æå¤±è´¥ - {e}")
                continue

        if body.empty:
            st.warning(f"âš ï¸ {f.name}: æœªè§£æåˆ°ä»»ä½•äº§å“æ•°æ®")
            continue

        # åº—é“ºæŸ¥æ‰¾
        store_id, mapped_name = store_lookup(name_txt, store_map_df)
        final_name = mapped_name or name_txt

        # åˆ›å»ºè¾“å‡ºæ•°æ®æ¡†
        out = pd.DataFrame({
            "store_id": store_id,
            "name": final_name,
            "sales_id": sales_id,
            "order_date": order_date,
            "item_id": body.get("item_id"),
            "quantity": body.get("quantity"),
            "price": body.get("price")
        })

        # æœ€ç»ˆæ¸…ç† - ç§»é™¤å‰©ä½™çš„ç©ºè¡Œ
        out = out.dropna(subset=['item_id'])
        out = out[out['item_id'] != '']

        # æ˜¾ç¤ºç»“æœ
        info = f"**ğŸ“„ {f.name}** Â· ä¾›åº”å•†ï¼š**{active_vendor}**"
        if chosen_by_rows:
            info += "ï¼ˆè‡ªåŠ¨å›é€€ï¼šæŒ‰è§£æè¡Œæ•°åˆ¤å®šï¼‰"
        
        total_items = len(out)
        total_value = out['price'].sum() if 'price' in out.columns else 0
        missing_store = out['store_id'].isna().sum()
        
        info += f" Â· {total_items} é¡¹äº§å“"
        if total_value > 0:
            info += f" Â· æ€»å€¼: ${total_value:.2f}"
        if missing_store > 0:
            info += f" Â· âš ï¸ {missing_store} é¡¹ç¼ºå°‘store_id"
        
        st.markdown(info)
        st.dataframe(out, use_container_width=True)
        
        # ä¸‹è½½å•ä¸ªæ–‡ä»¶
        csv_data = out.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label=f"â¬‡ï¸ ä¸‹è½½ {Path(f.name).stem}.csv",
            data=csv_data,
            file_name=f"{Path(f.name).stem}.csv",
            mime="text/csv",
            key=f"dl_{f.name}"
        )

        results.append(out)

    # åˆå¹¶æ‰€æœ‰ç»“æœ
    if results:
        merged = pd.concat(results, ignore_index=True)
        # æœ€ç»ˆæ¸…ç†åˆå¹¶æ•°æ®
        merged = merged.dropna(subset=['item_id'])
        merged = merged[merged['item_id'] != '']
        
        st.markdown("---")
        total_value = merged['price'].sum() if 'price' in merged.columns else 0
        st.markdown(f"**ğŸ“Š åˆå¹¶ç»Ÿè®¡**: {len(merged)} é¡¹äº§å“ï¼Œæ€»å€¼ ${total_value:.2f}")
        
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½åˆå¹¶ CSVï¼ˆorders.csvï¼‰",
            merged.to_csv(index=False).encode("utf-8-sig"),
            file_name="orders.csv",
            mime="text/csv"
        )
    
    progress_bar.empty()
else:
    st.info("ğŸ“¤ ä¸Šä¼  PDF æ–‡ä»¶å¼€å§‹è§£æ")

# ä½¿ç”¨è¯´æ˜å’Œæ•…éšœæ’é™¤
with st.expander("ğŸ’¡ GitHubç¯å¢ƒä½¿ç”¨æŒ‡å—"):
    st.markdown("""
    **GitHubç¯å¢ƒå…¼å®¹ç‰ˆ (v5.4)**:
    - âœ… å…¼å®¹ Python 3.8+ 
    - âœ… è‡ªåŠ¨é™çº§åˆ° PyPDF2ï¼ˆå¦‚æœ pdftotext ä¸å¯ç”¨ï¼‰
    - âœ… å¢å¼ºé”™è¯¯å¤„ç†
    
    **å¦‚æœé‡åˆ°é—®é¢˜**:
    1. **PDFæå–å¤±è´¥**: å®‰è£… PyPDF2
       ```bash
       pip install PyPDF2
       ```
    
    2. **æ‰«æç‰ˆPDF**: éœ€è¦OCRå·¥å…·ï¼Œå»ºè®®è½¬æ¢ä¸ºæ–‡æœ¬ç‰ˆPDF
    
    3. **æƒé™é”™è¯¯**: ç¡®ä¿æœ‰æ–‡ä»¶å†™å…¥æƒé™
    
    **æ”¯æŒçš„PDFæ ¼å¼**:
    - æ–‡æœ¬å‹PDFï¼ˆæ¨èï¼‰
    - éƒ¨åˆ†å›¾åƒå‹PDFï¼ˆé€šè¿‡PyPDF2ï¼‰
    """)
